{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and cleanup Rockset query lambdas and collections\n",
    "\n",
    "This code is for analyzing Rockset query lambdas and collections to help determine\n",
    "how critical each one is to our infrastructure\n",
    "\n",
    "We'll also use this to delete some query lambdas that are clearly not used\n",
    "\n",
    "Note: rockset_queries.py is generated from rockset_queries.ipynb with the command:\n",
    "\n",
    "`jupyter nbconvert --to script rockset_queries.ipynb`.  It is there just for ease of\n",
    "code reviews, any edits/execution is intended to occur in rockset_queries.ipynb (which\n",
    "is the source of truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Any, Dict, List, NamedTuple\n",
    "\n",
    "import requests\n",
    "\n",
    "ROCKSET_API_KEY = os.environ.get(\"ROCKSET_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaQuery(NamedTuple):\n",
    "    name: str\n",
    "    workspace: str\n",
    "    state: str\n",
    "    created_at: str\n",
    "    last_updated: str\n",
    "    last_updated_by: str\n",
    "    version_count: int\n",
    "    collections: List[str]\n",
    "    last_executed: str\n",
    "    last_execution_error: str\n",
    "    description: str\n",
    "    human_description: str\n",
    "    sql: Dict[str, Any]\n",
    "    raw_response: Dict[str, Any]\n",
    "\n",
    "    def printfields(self, fields: List[str]) -> None:\n",
    "        print(f\"Query: {self.workspace}.{self.name}\")\n",
    "        for field in fields:\n",
    "            print(f\"  {field}: {getattr(self, field)}\")\n",
    "\n",
    "\n",
    "def get_description_from_query_sql(sql: str) -> str:\n",
    "    \"\"\"\n",
    "    Some queries have a description in the top lines of the SQL.\n",
    "    This function checks for that and returns the description.\n",
    "    \"\"\"\n",
    "    lines = sql.split(\"\\n\")\n",
    "    description = \"\"\n",
    "    for line in lines:\n",
    "        # Ignore if blank or whitespace line\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        if line.startswith(\"--\"):\n",
    "            # skip all the leading \"-\" characters\n",
    "            description += line.lstrip(\"-\").strip() + \" \"\n",
    "        else:\n",
    "            # We've reached actual code\n",
    "            break\n",
    "    return description.strip()\n",
    "\n",
    "\n",
    "def get_query_lambdas() -> Dict[str, LambdaQuery]:\n",
    "    url = \"https://api.usw2a1.rockset.com/v1/orgs/self/lambdas\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"ApiKey {ROCKSET_API_KEY}\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.text)\n",
    "\n",
    "    queries = {}\n",
    "    for lambdaquery in data[\"data\"]:\n",
    "        queries[f\"{lambdaquery['workspace']}.{lambdaquery['name']}\"] = LambdaQuery(\n",
    "            name=lambdaquery[\"name\"],\n",
    "            workspace=lambdaquery[\"workspace\"],\n",
    "            state=lambdaquery[\"latest_version\"][\"state\"],\n",
    "            created_at=lambdaquery[\"latest_version\"][\"created_at\"],\n",
    "            last_updated=lambdaquery[\"last_updated\"],\n",
    "            last_updated_by=lambdaquery[\"last_updated_by\"],\n",
    "            version_count=lambdaquery[\"version_count\"],\n",
    "            collections=lambdaquery[\"latest_version\"][\"collections\"],\n",
    "            last_executed=lambdaquery[\"latest_version\"][\"stats\"][\"last_executed\"],\n",
    "            last_execution_error=lambdaquery[\"latest_version\"][\"stats\"][\n",
    "                \"last_execution_error\"\n",
    "            ],\n",
    "            description=lambdaquery[\"latest_version\"][\"description\"],\n",
    "            human_description=get_description_from_query_sql(\n",
    "                lambdaquery[\"latest_version\"][\"sql\"][\"query\"]\n",
    "            ),\n",
    "            sql=lambdaquery[\"latest_version\"][\"sql\"],\n",
    "            raw_response=lambdaquery,\n",
    "        )\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collections(NamedTuple):\n",
    "    name: str\n",
    "    workspace: str\n",
    "    created_at: str\n",
    "    created_by: str\n",
    "    last_queried: str\n",
    "    last_queried_raw: int\n",
    "    doc_count: int\n",
    "    description: str\n",
    "    status: str\n",
    "    size: int\n",
    "    raw_response: Dict[str, Any]\n",
    "\n",
    "\n",
    "def get_collections() -> Dict[str, Collections]:\n",
    "    url = \"https://api.usw2a1.rockset.com/v1/orgs/self/collections\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"ApiKey {ROCKSET_API_KEY}\",\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = json.loads(response.text)\n",
    "    print(json.dumps(data, indent=2))\n",
    "\n",
    "    collections = {}\n",
    "    for collection in data[\"data\"]:\n",
    "        # skip the collection \"commons._events\" since it's not a user-created collection\n",
    "        if collection[\"workspace\"] == \"commons\" and collection[\"name\"] == \"_events\":\n",
    "            continue\n",
    "\n",
    "        collections[f\"{collection['workspace']}.{collection['name']}\"] = Collections(\n",
    "            name=collection[\"name\"],\n",
    "            workspace=collection[\"workspace\"],\n",
    "            created_at=collection[\"created_at\"],\n",
    "            created_by=collection[\"created_by\"],\n",
    "            last_queried=str(\n",
    "                datetime.datetime.fromtimestamp(\n",
    "                    collection[\"stats\"][\"last_queried_ms\"] / 1000\n",
    "                )\n",
    "            ),\n",
    "            last_queried_raw=collection[\"stats\"][\"last_queried_ms\"],\n",
    "            size=collection[\"stats\"][\"total_size\"],\n",
    "            doc_count=collection[\"stats\"][\"doc_count\"],\n",
    "            description=collection.get(\"description\", \"\"),\n",
    "            status=collection[\"status\"],\n",
    "            raw_response=collection,\n",
    "        )\n",
    "\n",
    "    # sort collections by key\n",
    "    collections = dict(sorted(collections.items()))\n",
    "    return collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_human_descriptions(queries: Dict[str, LambdaQuery]) -> None:\n",
    "    for k, query in queries.items():\n",
    "        if query.human_description:\n",
    "            print(f\"{k}:\\n {query.human_description}\")\n",
    "\n",
    "\n",
    "def have_human_descriptions(queries: Dict[str, LambdaQuery]) -> Dict[str, LambdaQuery]:\n",
    "    \"\"\"Returns a dict of queries that have human descriptions\"\"\"\n",
    "    return {k: v for k, v in queries.items() if v.human_description}\n",
    "\n",
    "\n",
    "def inactive_queries(queries: Dict[str, LambdaQuery]) -> Dict[str, LambdaQuery]:\n",
    "    return {k: v for k, v in queries.items() if v.state != \"ACTIVE\"}\n",
    "\n",
    "\n",
    "def not_run(info: Dict[str, LambdaQuery]) -> Dict[str, LambdaQuery]:\n",
    "    \"\"\"Queries that have never been run.\"\"\"\n",
    "    return {k: v for k, v in info.items() if v.last_executed is None}\n",
    "\n",
    "\n",
    "def not_recently_run(info: Dict[str, LambdaQuery], days: int) -> Dict[str, LambdaQuery]:\n",
    "    \"\"\"Queries that have not been run in the last `days` days.\"\"\"\n",
    "    cutoff = datetime.datetime.now() - datetime.timedelta(days=days)\n",
    "    return {\n",
    "        k: v\n",
    "        for k, v in info.items()\n",
    "        if v.last_executed is not None\n",
    "        and datetime.datetime.strptime(v.last_executed, \"%Y-%m-%dT%H:%M:%SZ\") < cutoff\n",
    "    }\n",
    "\n",
    "\n",
    "def queries_run_recently(\n",
    "    queries: Dict[str, LambdaQuery], days: int\n",
    ") -> Dict[str, LambdaQuery]:\n",
    "    \"\"\"Queries that have been run in the last `days` days.\"\"\"\n",
    "    cutoff = datetime.datetime.now() - datetime.timedelta(days=days)\n",
    "    return {\n",
    "        k: v\n",
    "        for k, v in queries.items()\n",
    "        if v.last_executed is not None\n",
    "        and datetime.datetime.strptime(v.last_executed, \"%Y-%m-%dT%H:%M:%SZ\") > cutoff\n",
    "    }\n",
    "\n",
    "\n",
    "def not_in(\n",
    "    queries: Dict[str, LambdaQuery], excepting: Dict[str, LambdaQuery]\n",
    ") -> Dict[str, LambdaQuery]:\n",
    "    \"\"\"Returns LambdaQueries that are not in the excepting dictionary.\"\"\"\n",
    "    return {k: v for k, v in queries.items() if k not in excepting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_lambda(query: LambdaQuery) -> None:\n",
    "    url = f\"https://api.usw2a1.rockset.com/v1/orgs/self/ws/{query.workspace}/lambdas/{query.name}\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"ApiKey {ROCKSET_API_KEY}\",\n",
    "    }\n",
    "\n",
    "    response = requests.delete(url, headers=headers)\n",
    "    print(response.text)\n",
    "\n",
    "\n",
    "def backup_lambdas(queries: Dict[str, LambdaQuery], dir: Path) -> None:\n",
    "    # Create dir if it doesn't exist\n",
    "    dir.mkdir(parents=True, exist_ok=True)\n",
    "    for query in queries.values():\n",
    "        with open(dir / f\"{query.workspace}.{query.name}.sql.json\", \"w\") as f:\n",
    "            f.write(json.dumps(query.sql, indent=2))\n",
    "        with open(dir / f\"{query.workspace}.{query.name}.raw.json\", \"w\") as f:\n",
    "            f.write(json.dumps(query.raw_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = get_query_lambdas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_lambdas(queries, Path(\"lambdas_backup\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_unneeded = {\n",
    "    **not_run(queries),\n",
    "    **not_recently_run(queries, 60),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will be used to delete unused lambads, 10 at a time\n",
    "\n",
    "# # Deletes lambadas that have never been run\n",
    "# deletable = not_run(queries)\n",
    "\n",
    "# # Sort deletable by their last updated date\n",
    "# deletable = dict(sorted(deletable.items(), key=lambda x: x[1].last_updated))\n",
    "\n",
    "# # We'll delete the first 10 queries\n",
    "# for k, v in list(deletable.items())[:10]:\n",
    "#     print(f\"Deleting {k}\")\n",
    "#     delete_lambda(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_queries = not_in(queries, prob_unneeded)\n",
    "\n",
    "len(have_human_descriptions(important_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printq(queries: Dict[str, LambdaQuery], fields: List[str]) -> None:\n",
    "    for query in queries.values():\n",
    "        query.printfields(fields)\n",
    "        print()\n",
    "\n",
    "\n",
    "def print_query_descriptions(queries: Dict[str, LambdaQuery]) -> None:\n",
    "    for query in queries.values():\n",
    "        print(f\"{query.workspace}.{query.name}\", end=\"\")\n",
    "        if query.human_description:\n",
    "            print(f\" - {query.human_description}\")\n",
    "        elif query.description:\n",
    "            print(f\" - {query.description}\")\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "\n",
    "occasionally_run = not_in(important_queries, queries_run_recently(queries, 7))\n",
    "len(occasionally_run)\n",
    "\n",
    "len(occasionally_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = get_collections()\n",
    "len(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all collections in collections that are not in any collection\n",
    "# used by the important_queries\n",
    "def unused_collections(\n",
    "    collections: Dict[str, Collections], queries: Dict[str, LambdaQuery]\n",
    ") -> Dict[str, Collections]:\n",
    "    used_collections = set()\n",
    "    for query in queries.values():\n",
    "        used_collections.update(query.collections)\n",
    "    return {k: v for k, v in collections.items() if k not in used_collections}\n",
    "\n",
    "\n",
    "def used_collections(\n",
    "    collections: Dict[str, Collections], queries: Dict[str, LambdaQuery]\n",
    ") -> Dict[str, Collections]:\n",
    "    used_collections = set()\n",
    "    for query in queries.values():\n",
    "        used_collections.update(query.collections)\n",
    "    return {k: v for k, v in collections.items() if k in used_collections}\n",
    "\n",
    "\n",
    "print(\"Used collections:\")\n",
    "for collection in used_collections(collections, important_queries).values():\n",
    "    print(f\"{collection.workspace}.{collection.name}\")\n",
    "\n",
    "print(\"\\nUnused collections:\")\n",
    "for collection in unused_collections(collections, important_queries).values():\n",
    "    print(f\"{collection.workspace}.{collection.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
