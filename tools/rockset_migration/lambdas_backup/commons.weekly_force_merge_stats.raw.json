{
  "workspace": "commons",
  "last_updated_by": "zainriz3@gmail.com",
  "last_updated": "2023-10-02T16:45:55Z",
  "name": "weekly_force_merge_stats",
  "version_count": 1,
  "collections": [
    "commons.merges",
    "commons.issue_comment"
  ],
  "latest_version": {
    "workspace": "commons",
    "created_by": "zainriz3@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2023-10-02T16:45:55Z",
    "name": "weekly_force_merge_stats",
    "version": "d2264131599bcf6e",
    "description": "Force merge KPI stats for HUD",
    "sql": {
      "query": "-- Gets percentage of total force merges, force merges with failures, and force merges without failures (impatient)\n-- Specifically this query tracks the force merges kpi and metric on HUD\n--\n-- Special params:\n--   one_bucket: If set to false, bucketizes the results over the requested granularity\n--               otherwise there is not bucketing\n--   merge_type: If set, will return only data about the requested force merge type.\n--               Can be one of: \"All\", \"Impatience\", \"Failures\", or \" \" (to get everything)\nWITH issue_comments AS (\n  SELECT\n    issue_comment.user.login,\n    issue_comment.author_association,\n    issue_comment.body,\n    issue_comment.issue_url,\n    issue_comment.html_url,\n    issue_comment.created,\n    CAST(\n      SUBSTR(\n        issue_comment.issue_url,\n        LENGTH(\n          'https://api.github.com/repos/pytorch/pytorch/issues/'\n        ) + 1\n      ) AS INT\n    ) AS pr_num\n  FROM\n    commons.issue_comment\n  WHERE\n    (\n      issue_comment.body LIKE '%pytorchbot merge%'\n      OR issue_comment.body LIKE '%pytorchmergebot merge%'\n    )\n    AND issue_comment.user.login NOT LIKE '%pytorch-bot%'\n    AND issue_comment.user.login NOT LIKE '%facebook-github-bot%'\n    AND issue_comment.user.login NOT LIKE '%pytorchmergebot%'\n    AND issue_comment.issue_url LIKE '%https://api.github.com/repos/pytorch/pytorch/issues/%'\n),\nall_merges AS (\n  SELECT\n    DISTINCT m.skip_mandatory_checks,\n    LENGTH(m.failed_checks) AS failed_checks_count,\n    LENGTH(m.ignore_current_checks) AS ignored_checks_count,\n    LENGTH(m.pending_checks) AS pending_checks_count,\n    m.ignore_current,\n    m.is_failed,\n    m.pr_num,\n    m.merge_commit_sha,\n    max(c.created) AS time,\n  FROM\n    commons.merges m\n    INNER JOIN issue_comments c ON m.pr_num = c.pr_num\n  WHERE\n    m.owner = 'pytorch'\n    AND m.project = 'pytorch'\n    AND m.merge_commit_sha != '' -- only consider successful merges\n    AND m._event_time >= PARSE_DATETIME_ISO8601(: startTime)\n    AND m._event_time < PARSE_DATETIME_ISO8601(: stopTime)\n  GROUP BY\n    m.skip_mandatory_checks,\n    m.failed_checks,\n    m.ignore_current,\n    m.is_failed,\n    m.pr_num,\n    m.merge_commit_sha,\n    m.ignore_current_checks,\n    m.pending_checks\n),\n-- A legit force merge needs to satisfy one of the two conditions below:\n-- 1. skip_mandatory_checks is true (-f) and failed_checks_count > 0 (with failures) or pending_checks_count > 0 (impatience).\n--    Under this condition, if a force merge (-f) is done when there is no failure and all jobs have finished, it's arguably\n--    just a regular merge in disguise.\n-- 2. ignore_current is true (-i) and is_failed is false (indicating a successful merge) and ignored_checks_count > 0 (has failures).\n--    As -i still waits for all remaining jobs to finish, this shouldn't be counted toward force merge due to impatience.\n--\n-- If none applies, the merge should be counted as a regular merge regardless of the use of -f or -i. We could track that\n-- (regular merges masquerading as force merges) to understand how devs use (or abuse) these flags, but that's arguably a\n-- different case altogether.\nmerges_identifying_force_merges AS (\n  SELECT\n    IF(\n      (\n        skip_mandatory_checks = true\n        AND (\n          failed_checks_count > 0\n          OR pending_checks_count > 0\n        )\n      )\n      OR (\n        ignore_current = true\n        AND is_failed = false\n        AND ignored_checks_count > 0 -- if no checks were ignored, it's not a force merge\n        ),\n      1,\n      0\n    ) AS force_merge,\n    failed_checks_count,\n    pr_num,\n    merge_commit_sha,\n    ignore_current,\n    ignored_checks_count,\n    time,\n  FROM\n    all_merges\n),\nresults AS (\n  SELECT\n    pr_num,\n    merge_commit_sha,\n    force_merge,\n    IF(\n      force_merge = 1\n      AND (\n        failed_checks_count > 0\n        OR ignored_checks_count > 0\n      ),\n      1,\n      0\n    ) AS force_merge_with_failures,\n    CAST(time as DATE) AS date\n  FROM\n    merges_identifying_force_merges\n  ORDER BY\n    date DESC\n),\nbucketed_counts AS (\n  SELECT\n    IF(\n      : one_bucket,\n      'Overall',\n      FORMAT_TIMESTAMP(\n        '%Y-%m-%d',\n        DATE_TRUNC(: granularity, date)\n      )\n    ) AS granularity_bucket,\n    SUM(force_merge_with_failures) AS with_failures_cnt,\n    SUM(force_merge) - SUM(force_merge_with_failures) AS impatience_cnt,\n    COUNT(*) AS total,\n    SUM(force_merge) AS total_force_merge_cnt\n  FROM\n    results\n  GROUP BY\n    granularity_bucket\n),\nrolling_raw_stats AS (\n  -- Average over the past buckets\n  SELECT\n    granularity_bucket,\n    SUM(with_failures_cnt) OVER(\n      ORDER BY\n        granularity_bucket ROWS 1 PRECEDING\n    ) AS with_failures_cnt,\n    SUM(impatience_cnt) OVER(\n      ORDER BY\n        granularity_bucket ROWS 1 PRECEDING\n    ) AS impatience_cnt,\n    SUM(total_force_merge_cnt) OVER(\n      ORDER BY\n        granularity_bucket ROWS 1 PRECEDING\n    ) AS total_force_merge_cnt,\n    SUM(total) OVER(\n      ORDER BY\n        granularity_bucket ROWS 1 PRECEDING\n    ) AS total,\n  FROM\n    bucketed_counts\n),\nstats_per_bucket AS (\n  SELECT\n    granularity_bucket,\n    with_failures_cnt * 100.0 / total AS with_failures_percent,\n    impatience_cnt * 100.0 / total AS impatience_percent,\n    total_force_merge_cnt * 100.0 / total AS force_merge_percent,\n  FROM\n    rolling_raw_stats\n),\nfinal_table AS (\n  (\n    SELECT\n      granularity_bucket,\n      with_failures_percent AS metric,\n      'From Failures' AS name\n    FROM\n      stats_per_bucket\n  )\n  UNION ALL\n    (\n      SELECT\n        granularity_bucket,\n        impatience_percent AS metric,\n        'From Impatience' AS name\n      FROM\n        stats_per_bucket\n    )\n  UNION ALL\n    (\n      SELECT\n        granularity_bucket,\n        force_merge_percent AS metric,\n        'All Force Merges' AS name\n      FROM\n        stats_per_bucket\n    )\n),\nfiltered_result AS (\n  SELECT\n    *\n  FROM\n    final_table\n  WHERE\n    TRIM(: merge_type) = ''\n    OR name LIKE CONCAT('%', : merge_type, '%')\n)\nSELECT\n  *\nFROM\n  filtered_result\nORDER BY\n  granularity_bucket DESC,\n  name",
      "default_parameters": [
        {
          "name": "granularity",
          "type": "string",
          "value": "week"
        },
        {
          "name": "merge_type",
          "type": "string",
          "value": "  "
        },
        {
          "name": "one_bucket",
          "type": "bool",
          "value": "False"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2023-04-27T00:00:00.000Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2024-06-01T00:00:00.000Z"
        }
      ]
    },
    "collections": [
      "commons.issue_comment",
      "commons.merges"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T16:28:36Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-06-17T17:23:57Z",
      "last_execution_error_message": "No value specified for query parameter \"stopTime\". Please provide a value for this parameter and try again."
    },
    "public_access_id": null
  }
}