{
  "query": "WITH job AS (\n    SELECT\n        job.head_sha as sha,\n        job.name as job_name,\n        workflow.name as workflow_name,\n        job.id,\n        job.conclusion,\n        job.html_url as html_url,\n        IF(\n          :repo = 'pytorch/pytorch',\n          CONCAT(\n              'https://ossci-raw-job-status.s3.amazonaws.com/log/',\n              CAST(job.id as string)\n            ),\n          CONCAT(\n              'https://ossci-raw-job-status.s3.amazonaws.com/log/',\n              :repo,\n              '/',\n              CAST(job.id as string)\n            )\n          ) as log_url,\n        DATE_DIFF(\n            'SECOND',\n            PARSE_TIMESTAMP_ISO8601(job.started_at),\n            PARSE_TIMESTAMP_ISO8601(job.completed_at)\n        ) as duration_s,\n        workflow.repository.full_name as repo,\n        job.torchci_classification.line,\n        job.torchci_classification.captures,\n        job.torchci_classification.line_num,\n        annotation.annotation,\n    FROM\n        workflow_job job\n        INNER JOIN workflow_run workflow on workflow.id = job.run_id\n        LEFT JOIN job_annotation annotation ON job.id = annotation.jobID\n    WHERE\n        job.name != 'ciflow_should_run'\n        AND job.name != 'generate-test-matrix'\n        AND workflow.event != 'workflow_run' -- Filter out workflow_run-triggered jobs, which have nothing to do with the SHA\n        AND workflow.event != 'repository_dispatch' -- Filter out repository_dispatch-triggered jobs, which have nothing to do with the SHA\n        AND ARRAY_CONTAINS(SPLIT(:shas, ','), job.head_sha)\n        AND ARRAY_CONTAINS(SPLIT(:shas, ','), workflow.head_sha)\n        AND workflow.repository.full_name = :repo\n    UNION\n        -- Handle CircleCI\n        -- IMPORTANT: this needs to have the same order as the query above\n    SELECT\n        job.pipeline.vcs.revision as sha,\n        -- Swap workflow and job name for consistency with GHA naming style.\n        job.workflow.name as job_name,\n        job.job.name as workflow_name,\n        job.job.number as id,\n        case\n            WHEN job.job.status = 'failed' then 'failure'\n            WHEN job.job.status = 'canceled' then 'cancelled'\n            else job.job.status\n        END as conclusion,\n        -- cirleci doesn't provide a url, piece one together out of the info we have\n        CONCAT(\n            job.workflow.url,\n            '/jobs/',\n            CAST(job.job.number AS string)\n        ) as html_url,\n        -- logs aren't downloaded currently, just reuse html_url\n        html_url as log_url,\n        DATE_DIFF(\n            'SECOND',\n            PARSE_TIMESTAMP_ISO8601(job.job.started_at),\n            PARSE_TIMESTAMP_ISO8601(job.job.stopped_at)\n        ) as duration_s,\n        CONCAT(job.organization.name, '/', job.project.name) as repo,\n        null,\n        null,\n        null,\n        null,\n    FROM\n        circleci.job job\n    WHERE\n        ARRAY_CONTAINS(SPLIT(:shas, ','), job.pipeline.vcs.revision)\n        AND CONCAT(job.organization.name, '/', job.project.name) = :repo\n)\nSELECT\n    sha,\n    CONCAT(workflow_name, ' / ', job_name) as name,\n    id,\n    CASE\n        when conclusion is NULL then 'pending'\n        else conclusion\n    END as conclusion,\n    html_url as htmlUrl,\n    log_url as logUrl,\n    duration_s as durationS,\n    repo as repo,\n    ARRAY_CREATE(line) as failureLines,\n    ARRAY_CREATE(line_num) as failureLineNumbers,\n    captures as failureCaptures,\n    annotation as failureAnnotation,\nFROM\n    job\n",
  "default_parameters": [
    {
      "name": "repo",
      "type": "string",
      "value": "pytorch/pytorch"
    },
    {
      "name": "shas",
      "type": "string",
      "value": "90c8623c2ec874b5a1d7092a56a9a83abad78f78,b33831dcd89b99318b703b90c0fffee7bd710b2f"
    }
  ]
}