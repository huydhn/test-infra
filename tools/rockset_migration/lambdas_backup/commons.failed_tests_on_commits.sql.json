{
  "query": "WITH\n    -- Get all PRs that were merged into master, and get all the SHAs for commits\n    -- from that PR which CI jobs ran against.\n    pr_shas AS (\n        SELECT\n            r.pull_requests[1].number AS pr_number,\n            j.head_sha AS sha,\n        FROM\n            commons.workflow_job j\n            INNER JOIN commons.workflow_run r on j.run_id = r.id\n        WHERE\n            1 = 1\n            AND j._event_time > (\n                CURRENT_DATETIME() - DAYS(:days_back_start + :num_days_to_cover)\n            )\n            AND r._event_time > (\n                CURRENT_DATETIME() - DAYS(:days_back_start + :num_days_to_cover)\n            )\n            AND j._event_time < (CURRENT_DATETIME() - DAYS(:days_back_start))\n            AND r._event_time < (CURRENT_DATETIME() - DAYS(:days_back_start))\n            AND LENGTH(r.pull_requests) = 1 -- Some jobs have many PRs associated with them. They don't offer much of a signal to us\n            AND r.head_branch NOT IN ('master', 'main', 'nightly')\n            AND r.pull_requests[1].head.repo.name = 'pytorch'\n            AND r.name IN ('pull', 'trunk', 'Lint', 'periodic')\n            AND (\n                -- Ensure we don't pull in random PRs we don't care about\n                r.pull_requests[1].base.ref in ('master', 'main')\n                OR r.pull_requests[1].base.ref like 'gh/%/base'\n            )\n        GROUP BY\n            pr_number,\n            sha\n    ),\n    -- Get all the workflows and partially aggregate the jobs run against \n    -- each commit (based on the job's conclusion)\n    test_failures AS (\n        SELECT\n            s.pr_number,\n            s.sha,\n            f.failure,\n            f.invoking_file,\n            f.classname,\n            f.file as test_file,\n            min(j._event_time) AS start_time,\n            max(PARSE_TIMESTAMP_ISO8601(j.completed_at)) AS end_time,\n        FROM\n            commons.workflow_job j\n            INNER JOIN pr_shas s on j.head_sha = s.sha\n            INNER JOIN commons.workflow_run r on j.run_id = r.id\n            INNER JOIN commons.failed_tests_run f on f.job_id = j.id\n        WHERE\n            1 = 1\n            AND j._event_time > (\n                CURRENT_DATETIME() - DAYS(:days_back_start + :num_days_to_cover)\n            )\n            AND j._event_time < (CURRENT_DATETIME() - DAYS(:days_back_start))\n            AND (\n                r.name IN ('pull', 'trunk', 'Lint', 'periodic')\n                OR r.name like 'linux-binary%'\n                OR r.name like 'windows-binary%'\n            ) \n            AND j.conclusion NOT IN ('skipped')\n            AND f.failure is not NULL\n        GROUP BY\n            pr_number,\n            sha,\n            classname,\n            failure,\n            invoking_file,\n            test_file\n    )\nSELECT\n    *\nFROM\n    test_failures\norder by sha",
  "default_parameters": [
    {
      "name": "days_back_start",
      "type": "int",
      "value": "0"
    },
    {
      "name": "num_days_to_cover",
      "type": "int",
      "value": "6"
    },
    {
      "name": "repo_name",
      "type": "string",
      "value": "pytorch"
    },
    {
      "name": "repo_owner",
      "type": "string",
      "value": "pytorch"
    }
  ]
}