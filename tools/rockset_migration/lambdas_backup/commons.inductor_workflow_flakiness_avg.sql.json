{
  "query": "with jobs_with_flaky_annotation as (\n    select\n        job._event_time,\n        job.head_sha as sha,\n        FIRST_VALUE(job.conclusion) OVER(\n            PARTITION BY CONCAT(w.name, ' / ', job.name)\n            ORDER BY\n                job._event_time ROWS BETWEEN 1 PRECEDING\n                AND 1 FOLLOWING\n        ) = 'success'\n        and NTH_VALUE(job.conclusion, 2) OVER(\n            PARTITION BY CONCAT(w.name, ' / ', job.name)\n            ORDER BY\n                job._event_time ROWS BETWEEN 1 PRECEDING\n                AND 1 FOLLOWING\n        ) = 'failure'\n        and LAST_VALUE(job.conclusion) OVER(\n            PARTITION BY CONCAT(w.name, ' / ', job.name)\n            ORDER BY\n                job._event_time ROWS BETWEEN 1 PRECEDING\n                AND 1 FOLLOWING\n        ) = 'success' as flaky,\n        job.id,\n        w.head_branch,\n        CONCAT(w.name, ' / ', job.name) as jobName,\n        w.name as workflowName,\n        job.conclusion,\n        job.html_url as htmlUrl,\n        CONCAT(\n            'https://ossci-raw-job-status.s3.amazonaws.com/log/',\n            CAST(job.id as string)\n        ) as logUrl,\n        DATE_DIFF(\n            'SECOND',\n            PARSE_TIMESTAMP_ISO8601(job.started_at),\n            PARSE_TIMESTAMP_ISO8601(job.completed_at)\n        ) as durationS,\n        w.repository.full_name as repo,\n        job.torchci_classification.line as failureLine,\n        job.torchci_classification.captures as failureCaptures,\n        job.torchci_classification.line_num as failureLineNumber,\n    from\n        commons.workflow_job job\n        join commons.workflow_run w on w.id = job.run_id\n        and w.head_repository.full_name = 'pytorch/pytorch'\n    where\n        -- w.head_branch = :branch\n        -- and\n        job._event_time >= CURRENT_DATE() - INTERVAL 2 WEEK\n        and w.head_repository.full_name = 'pytorch/pytorch'\n        and w.head_branch = 'main'\n        and (\n            job.name like '%inductor%'\n            or w.name like '%inductor%'\n        )\n        and job.conclusion in ('success', 'failure')\n    order by\n        job._event_time\n),\nfailed_due_to_flaky_inductor as (\n    select\n        sha,\n        max(flaky) as flaky\n    from\n        jobs_with_flaky_annotation\n    group by\n        sha\n)\n\n-- Overall flakiness on trunk\nselect (select count(*) from failed_due_to_flaky_inductor where flaky) * 100.0/(select count(*) from failed_due_to_flaky_inductor)\n\n-- The flakiest jobs\n-- select AVG(CAST(flaky as FLOAT)) * 100.0 as failure_rate, jobName from jobs_with_flaky_annotation group by jobName order by failure_rate desc\n\n-- The specific runs that flaked\n-- select * from jobs_with_flaky_annotation where flaky\n",
  "default_parameters": []
}