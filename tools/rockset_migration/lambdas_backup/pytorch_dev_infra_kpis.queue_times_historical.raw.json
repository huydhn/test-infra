{
  "workspace": "pytorch_dev_infra_kpis",
  "last_updated_by": "eliuriegas@fb.com",
  "last_updated": "2022-09-09T20:55:45Z",
  "name": "queue_times_historical",
  "version_count": 7,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run"
  ],
  "latest_version": {
    "workspace": "pytorch_dev_infra_kpis",
    "created_by": "eliuriegas@fb.com",
    "created_by_apikey_name": null,
    "created_at": "2022-09-09T20:55:45Z",
    "name": "queue_times_historical",
    "version": "27bd325af2761b9e",
    "description": null,
    "sql": {
      "query": "SELECT\n    item.machine_type,\n    item.granularity_bucket,\n    AVG(item.queue_time) / 60 as average_queue_time\nFROM\n    (\n        SELECT            \n      \t\t-- Since we're grouping by run_url ARBITRARY(item.machine_type) should realistically only have 1 value\n            PERCENT_RANK() OVER (\n                PARTITION BY ARBITRARY(item.machine_type), item.granularity_bucket\n                ORDER BY SUM(item.queue_time)\n            ) AS percentile,\n            ARBITRARY(item.machine_type) as machine_type,\n            item.granularity_bucket,\n            SUM(item.queue_time) as queue_time\n        FROM\n            (\n                SELECT\n                    job.run_url,\n                    IF(\n                        LENGTH(job.labels) > 1,\n                        ELEMENT_AT(job.labels, 2),\n                        ELEMENT_AT(job.labels, 1)\n                    ) as machine_type,\n                    DATE_DIFF(\n                        'second',\n                        PARSE_DATETIME_ISO8601(workflow.created_at),\n                        PARSE_DATETIME_ISO8601(job.started_at)\n                    ) as queue_time,\n                    FORMAT_ISO8601(\n                        DATE_TRUNC(\n                            :granularity,\n                            job._event_time AT TIME ZONE :timezone\n                        )\n                    ) AS granularity_bucket,\n                FROM\n                    commons.workflow_job job\n                    JOIN commons.workflow_run workflow on workflow.url = job.run_url\n                WHERE\n                    job.status = 'queued'\n                    AND workflow.status = 'completed'\n                    AND LENGTH(job.labels) > 0\n                    AND job._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n                    AND job._event_time <= PARSE_DATETIME_ISO8601(:stopTime)\n                UNION\n                SELECT\n                    job.run_url,\n                    IF(\n                        LENGTH(job.labels) > 1,\n                        ELEMENT_AT(job.labels, 2),\n                        ELEMENT_AT(job.labels, 1)\n                    ) as machine_type,\n                    0 AS queue_time,\n                    FORMAT_ISO8601(\n                        DATE_TRUNC(\n                            :granularity,\n                            job._event_time AT TIME ZONE :timezone\n                        )\n                    ) AS granularity_bucket,\n                FROM\n                    commons.workflow_job job\n                    JOIN commons.workflow_run workflow on workflow.url = job.run_url\n                WHERE\n                    job.status = 'completed'\n                    AND workflow.status = 'completed'\n                    AND LENGTH(job.labels) > 0\n                    AND job._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n                    AND job._event_time <= PARSE_DATETIME_ISO8601(:stopTime)\n            ) item\n      \t\tGROUP BY\n      \t\t\titem.run_url,\n      \t\t\titem.granularity_bucket\n    ) item\nWHERE\n    (\n        SELECT\n            NOT IS_NAN(item.percentile)\n            AND item.percentile >= (1.0 - :percentile)\n    )\nGROUP BY\n    item.machine_type,\n    item.granularity_bucket\n",
      "default_parameters": [
        {
          "name": "granularity",
          "type": "string",
          "value": "week"
        },
        {
          "name": "percentile",
          "type": "float",
          "value": "0.9"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2022-01-01T00:00:00.000Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2023-01-01T00:00:00.000Z"
        },
        {
          "name": "timezone",
          "type": "string",
          "value": "America/Los_Angeles"
        }
      ]
    },
    "collections": [
      "commons.workflow_run",
      "commons.workflow_job"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": null,
      "last_executed_by": null,
      "last_execution_error": null,
      "last_execution_error_message": null
    },
    "public_access_id": null
  }
}