{
  "workspace": "metrics",
  "last_updated_by": "nikita.shulga@gmail.com",
  "last_updated": "2023-04-17T14:25:24Z",
  "name": "num_tests_run",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.test_run_summary",
    "commons.workflow_run",
    "commons.push"
  ],
  "latest_version": {
    "workspace": "metrics",
    "created_by": "nikita.shulga@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2023-04-17T14:25:24Z",
    "name": "num_tests_run",
    "version": "148e44c8f1ab7517",
    "description": null,
    "sql": {
      "query": "WITH most_recent_commits AS (\n    SELECT\n        push.head_commit.id AS sha,\n        push._event_time\n    FROM\n        commons.push\n    WHERE\n        push.ref = 'refs/heads/main'\n        AND push.repository.full_name = 'pytorch/pytorch'\n        AND push._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n        AND push._event_time < PARSE_DATETIME_ISO8601(:stopTime)\n    ORDER BY\n        push._event_time DESC\n),\njob AS (\n    SELECT\n        w.id AS workflow_id,\n        w.name AS workflow_name,\n        SUM(test_run.tests) AS num_tests,\n        j.head_sha AS sha,\n    FROM\n        most_recent_commits commits\n        JOIN commons.workflow_run w ON w.head_sha = commits.sha\n        JOIN commons.workflow_job j ON w.id = j.run_id\n        LEFT JOIN commons.test_run_summary test_run ON j.id = test_run.job_id\n    GROUP BY\n        workflow_id,\n        workflow_name,\n        sha\n    HAVING\n        BOOL_AND(\n            (\n                j.conclusion = 'success'\n                OR j.conclusion = 'skipped' -- sometimes there are jobs that get shown as skipped when they aren't supposed to run\n            )\n            AND j.conclusion IS NOT null\n        )\n),\nnum_tests AS (\n    SELECT\n        job.workflow_name,\n        Avg(job.num_tests) AS avg_num_tests,\n        DATE_TRUNC(:granularity, commits._event_time) AS push_event_time,\n    FROM\n        job\n        JOIN most_recent_commits commits ON commits.sha = job.sha\n    WHERE\n        num_tests IS NOT null\n    GROUP BY\n        DATE_TRUNC(:granularity, commits._event_time),\n        workflow_name\n    ORDER BY\n        workflow_name,\n        push_event_time\n)\nSELECT\n    workflow_name,\n    avg_num_tests,\n    avg_num_tests - LAG(avg_num_tests, 1) OVER (\n        PARTITION BY workflow_name\n        ORDER BY\n            push_event_time\n    ) AS change,\n    push_event_time\nFROM\n    num_tests\nORDER BY\n    workflow_name,\n    push_event_time\n",
      "default_parameters": [
        {
          "name": "granularity",
          "type": "string",
          "value": "hour"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2022-09-01T00:06:32.839Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2022-09-05T00:06:32.839Z"
        }
      ]
    },
    "collections": [
      "commons.push",
      "commons.test_run_summary",
      "commons.workflow_job",
      "commons.workflow_run"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-21T15:44:13Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-04-19T15:03:10Z",
      "last_execution_error_message": "Query timeout reached. To extend the query timeout, run an async query by setting `async` to true. Otherwise, please upgrade to a larger Virtual Instance or contact Rockset customer support for assistance constructing a more efficient query."
    },
    "public_access_id": null
  }
}