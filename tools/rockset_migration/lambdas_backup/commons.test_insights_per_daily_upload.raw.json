{
  "workspace": "commons",
  "last_updated_by": "sahanp@meta.com",
  "last_updated": "2023-05-04T20:14:19Z",
  "name": "test_insights_per_daily_upload",
  "version_count": 17,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "commons.test_run_summary"
  ],
  "latest_version": {
    "workspace": "commons",
    "created_by": "sahanp@meta.com",
    "created_by_apikey_name": null,
    "created_at": "2023-05-04T20:14:19Z",
    "name": "test_insights_per_daily_upload",
    "version": "692684fa5b37177f",
    "description": null,
    "sql": {
      "query": "WITH\ntest_runs AS (\n    SELECT\n        workflow_run.name AS workflow_name,\n        workflow_job.name AS job_name,\n        workflow_run.id AS workflow_id,\n        test_run_summary.invoking_file AS test_file,\n        test_run_summary.classname AS test_class,\n        test_run_summary.tests AS tests,\n        test_run_summary.errors AS errors,\n        test_run_summary.failures AS failures,\n        test_run_summary.skipped AS skipped,\n        test_run_summary.time AS duration_in_second,\n        test_run_summary.workflow_run_attempt AS workflow_run_attempt\n    FROM\n        commons.test_run_summary\n        JOIN commons.workflow_run on test_run_summary.workflow_id = CAST(workflow_run.id as string)\n        JOIN commons.workflow_job on test_run_summary.job_id = workflow_job.id\n    WHERE\n        test_run_summary._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n        AND test_run_summary._event_time < PARSE_DATETIME_ISO8601(:startTime) + INTERVAL 1 DAY\n        AND (workflow_run.head_branch = 'main' OR workflow_run.head_branch = 'master')\n        AND workflow_run.conclusion = 'success'\n        AND workflow_run.head_repository.full_name = 'pytorch/pytorch'\n),\naggregated_test_runs AS (\n    SELECT\n        PARSE_DATETIME_ISO8601(:startTime) as date,\n        REGEXP_EXTRACT(job_name, '^(.*) /', 1) as base_name,\n        REGEXP_EXTRACT(job_name, '/ test \\((\\w*),', 1) as test_config,\n        workflow_name,\n        job_name,\n        test_file,\n        test_class,\n        workflow_id,\n        workflow_run_attempt,\n        CAST(SUM(duration_in_second) AS int) sum_duration_in_second,\n        CAST(SUM(tests) AS int) AS sum_tests,\n        MAX(failures) AS max_failures,\n        MAX(errors) AS max_errors,\n        CAST(SUM(skipped) AS int) AS sum_skipped,\n        COUNT(duration_in_second) AS occurences\n    FROM\n        test_runs\n    GROUP BY\n        workflow_name,\n        job_name,\n        test_file,\n        test_class,\n        workflow_id,\n        workflow_run_attempt\n)\nSELECT\n    *\nFROM\n    aggregated_test_runs\nORDER BY\n    sum_duration_in_second DESC\n",
      "default_parameters": [
        {
          "name": "startTime",
          "type": "string",
          "value": "2023-04-24T00:00:00.000Z"
        }
      ]
    },
    "collections": [
      "commons.workflow_job",
      "commons.workflow_run",
      "commons.test_run_summary"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T07:40:56Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-01-18T07:42:54Z",
      "last_execution_error_message": "Query timeout reached. To extend the query timeout, run an async query by setting `async` to true. Otherwise, please upgrade to a larger Virtual Instance or contact Rockset customer support for assistance constructing a more efficient query."
    },
    "public_access_id": null
  }
}