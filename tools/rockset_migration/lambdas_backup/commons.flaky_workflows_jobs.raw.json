{
  "workspace": "commons",
  "last_updated_by": "huydhn@gmail.com",
  "last_updated": "2023-08-25T19:38:04Z",
  "name": "flaky_workflows_jobs",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "commons.job_annotation",
    "commons.push"
  ],
  "latest_version": {
    "workspace": "commons",
    "created_by": "huydhn@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2023-08-25T19:38:04Z",
    "name": "flaky_workflows_jobs",
    "version": "3ac657ca40327f94",
    "description": null,
    "sql": {
      "query": "-- This query is used to get flaky job on trunk so that they can be retried. A flaky job is the\n-- one that has the green / red / green pattern. The failure in the middle is considered flaky\n-- and can be retried\nWITH dedups AS (\n  -- Note that there can be more than one commit with the same ID with the actual author and pytorchmergebot.\n  -- This mess up the results in some cases, so this removes all redundant information and only keeps what is\n  -- needed for the later query\n  SELECT\n    DISTINCT CONCAT(w.name, ' / ', job.name) AS fullname,\n    w.name AS workflow_name,\n    w.id AS workflow_id,\n    job.name AS job_name,\n    job.id AS job_id,\n    job.conclusion AS conclusion,\n    push.head_commit.id AS head_commit,\n    push.head_commit.timestamp AS head_commit_timestamp,\n    job.run_attempt AS run_attempt,\n    ROW_NUMBER() OVER(\n      PARTITION BY w.id,\n      w.name,\n      job.name\n      ORDER BY\n        job.run_attempt DESC\n    ) AS row_num,\n  FROM\n    commons.workflow_run w\n    JOIN commons.workflow_job job ON w.id = job.run_id HINT(join_strategy = lookup)\n    JOIN push ON push.head_commit.id = w.head_commit.id\n  WHERE\n    (\n      job._event_time >= CURRENT_DATE() - HOURS(: numHours)\n      OR : numHours = 0\n    )\n    AND w.head_repository.full_name = : repo\n    AND ARRAY_CONTAINS(\n      SPLIT(: branches, ','),\n      w.head_branch\n    )\n    AND ARRAY_CONTAINS(\n      SPLIT(: workflowNames, ','),\n      w.name\n    )\n    AND job.name NOT LIKE '%mem_leak_check%'\n    AND job.name NOT LIKE '%rerun_disabled_tests%'\n    AND job.name NOT LIKE '%unstable%'\n),\nlatest_attempts AS (\n  -- Keep the latest run attempt to know if the job has already been retried\n  SELECT\n    *\n  FROM\n    dedups\n  WHERE\n    row_num = 1\n),\nflaky_jobs AS (\n  SELECT\n    workflow_name,\n    job_name,\n    -- Next commit\n    workflow_id AS next_workflow_id,\n    job_id AS next_job_id,\n    -- The flaky status of the job\n    FIRST_VALUE(conclusion) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) = 'success'\n    AND NTH_VALUE(conclusion, 2) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) = 'failure'\n    AND LAST_VALUE(conclusion) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) = 'success' AS flaky,\n    -- The current commit\n    NTH_VALUE(workflow_id, 2) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) AS workflow_id,\n    NTH_VALUE(job_id, 2) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) AS job_id,\n    NTH_VALUE(run_attempt, 2) OVER(\n      PARTITION BY fullname\n      ORDER BY\n        head_commit_timestamp DESC ROWS BETWEEN CURRENT ROW\n        AND 2 FOLLOWING\n    ) AS run_attempt,\n  FROM\n    latest_attempts\n  WHERE\n    (\n      latest_attempts.run_attempt <= : maxAttempt\n      OR : maxAttempt = 0\n    )\n)\nSELECT\n  DISTINCT flaky_jobs.workflow_name,\n  flaky_jobs.workflow_id,\n  flaky_jobs.job_name,\n  flaky_jobs.job_id,\n  flaky_jobs.flaky,\n  flaky_jobs.run_attempt,\n  flaky_jobs.next_workflow_id,\n  flaky_jobs.next_job_id,\n  annotation.annotation,\nFROM\n  flaky_jobs\n  LEFT JOIN commons.job_annotation annotation on annotation.jobID = flaky_jobs.job_id\nWHERE\n  (\n    (\n      flaky_jobs.flaky\n      AND annotation.annotation IS NULL\n    )\n    OR annotation.annotation = 'TEST_FLAKE'\n  )\n  AND (\n    flaky_jobs.workflow_id = : workflowId\n    OR : workflowId = 0\n  )\n  AND (\n    flaky_jobs.next_workflow_id = : nextWorkflowId\n    OR : nextWorkflowId = 0\n  )",
      "default_parameters": [
        {
          "name": "branches",
          "type": "string",
          "value": "master,main"
        },
        {
          "name": "maxAttempt",
          "type": "int",
          "value": "1"
        },
        {
          "name": "nextWorkflowId",
          "type": "int",
          "value": "0"
        },
        {
          "name": "numHours",
          "type": "int",
          "value": "24"
        },
        {
          "name": "repo",
          "type": "string",
          "value": "pytorch/pytorch"
        },
        {
          "name": "workflowId",
          "type": "int",
          "value": "0"
        },
        {
          "name": "workflowNames",
          "type": "string",
          "value": "pull,trunk"
        }
      ]
    },
    "collections": [
      "commons.job_annotation",
      "commons.push",
      "commons.workflow_job",
      "commons.workflow_run"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T16:27:45Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-06-25T09:24:35Z",
      "last_execution_error_message": "RESOURCE_EXHAUSTED: The instance size you are using does not have the memory capacity to execute the current workload. Please upgrade to a larger instance size, or reduce the rate or complexity of the queries you are running."
    },
    "public_access_id": null
  }
}