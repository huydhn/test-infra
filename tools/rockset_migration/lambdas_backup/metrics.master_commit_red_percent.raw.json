{
  "workspace": "metrics",
  "last_updated_by": "huydhn@gmail.com",
  "last_updated": "2023-06-01T21:34:41Z",
  "name": "master_commit_red_percent",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "circleci.job",
    "commons.push"
  ],
  "latest_version": {
    "workspace": "metrics",
    "created_by": "huydhn@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2023-06-01T21:34:41Z",
    "name": "master_commit_red_percent",
    "version": "5c1de222caaf3a9e",
    "description": null,
    "sql": {
      "query": "WITH all_jobs AS (\n    SELECT\n        push._event_time as time,\n        job.conclusion AS conclusion,\n        push.head_commit.id AS sha,\n        ROW_NUMBER() OVER(PARTITION BY job.name, push.head_commit.id ORDER BY job.run_attempt DESC) AS row_num,\n    FROM\n        push\n        JOIN commons.workflow_run workflow ON workflow.head_commit.id = push.head_commit.id\n        JOIN commons.workflow_job job ON workflow.id = job.run_id\n    WHERE\n        job.name != 'ciflow_should_run'\n        AND job.name != 'generate-test-matrix'\n        AND ( -- Limit it to workflows which block viable/strict upgrades\n            ARRAY_CONTAINS(SPLIT(:workflowNames, ','), LOWER(workflow.name))\n            OR workflow.name like 'linux-binary%'\n        )\n        AND job.name NOT LIKE '%rerun_disabled_tests%'\n        AND job.name NOT LIKE '%unstable%'\n        AND workflow.event != 'workflow_run' -- Filter out worflow_run-triggered jobs, which have nothing to do with the SHA\n        AND push.ref IN ('refs/heads/master', 'refs/heads/main')\n        AND push.repository.owner.name = 'pytorch'\n        AND push.repository.name = 'pytorch'\n        AND push._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n        AND push._event_time < PARSE_DATETIME_ISO8601(:stopTime)\n    UNION ALL\n    SELECT\n        push._event_time as time,\n        CASE\n            WHEN job.job.status = 'failed' then 'failure'\n            WHEN job.job.status = 'canceled' then 'cancelled'\n            ELSE job.job.status\n        END AS conclusion,\n        push.head_commit.id AS sha,\n        ROW_NUMBER() OVER(PARTITION BY job.name, push.head_commit.id ORDER BY job.run_attempt DESC) AS row_num,\n    FROM\n        circleci.job job\n        JOIN push ON job.pipeline.vcs.revision = push.head_commit.id\n    WHERE\n        push.ref IN ('refs/heads/master', 'refs/heads/main')\n        AND push.repository.owner.name = 'pytorch'\n        AND push.repository.name = 'pytorch'\n        AND push._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n        AND push._event_time < PARSE_DATETIME_ISO8601(:stopTime)\n),\nany_red AS (\n    SELECT\n        FORMAT_TIMESTAMP('%Y-%m-%d', DATE_TRUNC(:granularity, time)) AS granularity_bucket,\n        sha,\n        CAST(\n            SUM(\n                CASE\n                    WHEN conclusion = 'failure' THEN 1\n                    WHEN conclusion = 'timed_out' THEN 1\n                    WHEN conclusion = 'cancelled' THEN 1\n                    ELSE 0\n                END\n            ) > 0 AS int\n        ) AS all_red,\n        CAST(\n            SUM(\n                CASE\n                    WHEN conclusion = 'failure' AND row_num = 1 THEN 1\n                    WHEN conclusion = 'timed_out' AND row_num = 1 THEN 1\n                    WHEN conclusion = 'cancelled' AND row_num = 1 THEN 1\n                    ELSE 0\n                END\n            ) > 0 AS int\n        ) AS broken_trunk_red,\n    FROM\n        all_jobs\n    GROUP BY\n        granularity_bucket,\n        sha\n    HAVING\n        count(sha) > 10 -- Filter out jobs that didn't run anything.\n        AND SUM(IF(conclusion is NULL, 1, 0)) = 0 -- Filter out commits that still have pending jobs.\n),\nclassified_red AS (\n    SELECT\n        granularity_bucket,\n        ARRAY_CREATE(\n            ARRAY_CREATE('Broken trunk', AVG(broken_trunk_red)),\n            ARRAY_CREATE('Flaky', AVG(all_red) - AVG(broken_trunk_red)),\n            ARRAY_CREATE('Total', AVG(all_red))\n        ) AS metrics,\n    FROM\n        any_red\n    GROUP BY\n        granularity_bucket\n),\navg_red AS (\n    SELECT\n        classified_red.granularity_bucket,\n        ELEMENT_AT(metrics.metric, 1) AS name,\n        ELEMENT_AT(metrics.metric, 2) AS metric,\n    FROM\n        classified_red\n        CROSS JOIN UNNEST(classified_red.metrics AS metric) AS metrics\n    ORDER BY\n        granularity_bucket DESC\n)\nSELECT\n    granularity_bucket,\n    name,\n    -- 2 week rolling average\n    (\n        SUM(metric) OVER(\n            PARTITION BY name\n            ORDER BY\n                granularity_bucket ROWS 1 PRECEDING\n        )\n    ) / 2.0 AS metric,    \nFROM\n    avg_red",
      "default_parameters": [
        {
          "name": "granularity",
          "type": "string",
          "value": "week"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2023-02-01T00:00:00.000Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2023-03-30T00:00:00.000Z"
        },
        {
          "name": "workflowNames",
          "type": "string",
          "value": "lint,pull,trunk"
        }
      ]
    },
    "collections": [
      "circleci.job",
      "commons.workflow_job",
      "commons.workflow_run",
      "commons.push"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T13:36:44Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-03-05T08:49:16Z",
      "last_execution_error_message": "RESOURCE_EXHAUSTED: The instance size you are using does not have the memory capacity to execute the current workload. Please upgrade to a larger instance size, or reduce the rate or complexity of the queries you are running. This occurred while running HashJoinOperator."
    },
    "public_access_id": null
  }
}