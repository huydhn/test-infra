{
  "workspace": "pytorch_dev_infra_kpis",
  "last_updated_by": "eliuriegas@fb.com",
  "last_updated": "2022-09-16T16:20:47Z",
  "name": "get_all_queue_times_historical",
  "version_count": 3,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run"
  ],
  "latest_version": {
    "workspace": "pytorch_dev_infra_kpis",
    "created_by": "eliuriegas@fb.com",
    "created_by_apikey_name": null,
    "created_at": "2022-09-16T16:20:47Z",
    "name": "get_all_queue_times_historical",
    "version": "79ae8b92337d65b5",
    "description": null,
    "sql": {
      "query": "SELECT\n    ARBITRARY(item.machine_type) as machine_type,\n    SUM(item.queue_time) as queue_time,\n    item.granularity_bucket as granularity_bucket\nFROM\n    (\n        SELECT\n            job.run_url,\n            IF(\n                LENGTH(job.labels) > 1,\n                ELEMENT_AT(job.labels, 2),\n                ELEMENT_AT(job.labels, 1)\n            ) as machine_type,\n            DATE_DIFF(\n                'second',\n                PARSE_DATETIME_ISO8601(workflow.created_at),\n                PARSE_DATETIME_ISO8601(job.started_at)\n            ) as queue_time,\n            FORMAT_ISO8601(\n                DATE_TRUNC(\n                    :granularity,\n                    job._event_time AT TIME ZONE :timezone\n                )\n            ) AS granularity_bucket,\n        FROM\n            commons.workflow_job job\n            JOIN commons.workflow_run workflow on workflow.url = job.run_url\n        WHERE\n            job.status = 'queued'\n            AND LENGTH(job.labels) > 0\n            AND job._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n            AND job._event_time <= PARSE_DATETIME_ISO8601(:stopTime)\n        UNION\n        SELECT\n            job.run_url,\n            IF(\n                LENGTH(job.labels) > 1,\n                ELEMENT_AT(job.labels, 2),\n                ELEMENT_AT(job.labels, 1)\n            ) as machine_type,\n            0 AS queue_time,\n            FORMAT_ISO8601(\n                DATE_TRUNC(\n                    :granularity,\n                    job._event_time AT TIME ZONE :timezone\n                )\n            ) AS granularity_bucket,\n        FROM\n            commons.workflow_job job\n            JOIN commons.workflow_run workflow on workflow.url = job.run_url\n        WHERE\n            job.status = 'completed'\n            AND workflow.status = 'completed'\n            AND LENGTH(job.labels) > 0\n            AND job._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n            AND job._event_time <= PARSE_DATETIME_ISO8601(:stopTime)\n    ) item\nGROUP BY\n    item.run_url,\n    item.granularity_bucket\n",
      "default_parameters": [
        {
          "name": "granularity",
          "type": "string",
          "value": "week"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2022-01-01T00:00:00.000Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2023-01-01T00:00:00.000Z"
        },
        {
          "name": "timezone",
          "type": "string",
          "value": "America/Los_Angeles"
        }
      ]
    },
    "collections": [
      "commons.workflow_run",
      "commons.workflow_job"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": null,
      "last_executed_by": null,
      "last_execution_error": null,
      "last_execution_error_message": null
    },
    "public_access_id": null
  }
}