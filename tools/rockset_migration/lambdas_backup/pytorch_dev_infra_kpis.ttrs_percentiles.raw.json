{
  "workspace": "pytorch_dev_infra_kpis",
  "last_updated_by": "csl@fb.com",
  "last_updated": "2024-03-19T20:15:27Z",
  "name": "ttrs_percentiles",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "commons.pull_request"
  ],
  "latest_version": {
    "workspace": "pytorch_dev_infra_kpis",
    "created_by": "csl@fb.com",
    "created_by_apikey_name": "AKey",
    "created_at": "2024-03-19T20:15:27Z",
    "name": "ttrs_percentiles",
    "version": "ea95e9b56ab6900f",
    "description": "Computes the TTRS kpi",
    "sql": {
      "query": "-- This query is used to compute the TTRS KPI for the pytorch/pytorch repo.\n--\n-- Results are displayed on HUD in two views:\n--   The kpi view, where percentile_to_get should be left at zero in order to get the default percentiles\n--   The metrics view, where the percentile_to_get and one_bucket should be set in order to get just the desired percentile\n--\n-- This query has two special params:\n--     percentile_to_get: When set, it returns only the specified percentile. Otherwise it returns\n--                 p25, p50, p75 and p90 percentiles.\n--     one_bucket: When set to false, buckets data into weekly percentiles. When true, it treats\n--                 entire time range AS one big bucket and returns percnetiles accordingly\n\nWITH\n-- All the percentiles that we want the query to determine\npercentiles_desired AS (\n  SELECT\n    CONCAT('p', n.percentile) as percentile,\n    n.percentile / 100.0 as percentile_num\n  FROM  UNNEST(ARRAY_CREATE(25, 50, 75, 90) AS percentile) AS n\n  UNION ALL\n    -- if percentile_to_get is specified, we get and only return that percentile\n  SELECT\n    CONCAT(\n      'p',\n      CAST(\n        ROUND(: percentile_to_get * 100) AS STRING\n      )\n    ),\n    : percentile_to_get\n  WHERE\n    : percentile_to_get > 0\n),\n-- Get all PRs that were merged into master, and get all the SHAs for commits from that PR which CI jobs ran against\n-- We need the shas because some jobs (like trunk) don't have a PR they explicitly ran against, but they _were_ run against\n-- a commit from a PR\npr_shas AS (\n  SELECT\n    r.pull_requests[1].number AS pr_number,\n    CONCAT(\n      'https://github.com/pytorch/pytorch/pull/',\n      r.pull_requests[1].number\n    ) AS url,\n    j.head_sha AS sha,\n  FROM\n    commons.workflow_job j\n    INNER JOIN commons.workflow_run r ON j.run_id = r.id\n  WHERE\n    1 = 1\n    AND j._event_time > PARSE_DATETIME_ISO8601(: startTime)\n    AND r._event_time > PARSE_DATETIME_ISO8601(: startTime)\n    AND j._event_time < PARSE_DATETIME_ISO8601(: stopTime)\n    AND r._event_time < PARSE_DATETIME_ISO8601(: stopTime)\n    AND LENGTH(r.pull_requests) = 1\n    AND r.pull_requests[1].head.repo.name = 'pytorch'\n    AND r.name IN ('pull', 'trunk', 'Lint') -- Ensure we don't pull in random PRs we don't care about\n    AND r.head_branch NOT IN (\n      'master', 'main', 'nightly', 'viable/strict'\n    ) -- Only measure TTRS against PRs\n    AND (\n      r.pull_requests[1].base.ref = 'master'\n      OR r.pull_requests[1].base.ref = 'main'\n      OR r.pull_requests[1].base.ref like 'gh/%/base'\n    )\n  GROUP BY\n    pr_number,\n    url,\n    sha\n),\n-- Now filter the list to just closed PRs.\n-- Open PRs can be noisy experiments which were never meant to be merged.\nmerged_pr_shas AS (\n  SELECT\n    DISTINCT s.pr_number,\n    s.url,\n    s.sha\n  FROM\n    pr_shas s\n    INNER JOIN commons.pull_request pr ON s.pr_number = pr.number\n  WHERE\n    pr.closed_at IS NOT NULL -- Ensure the PR was actaully merged\n    AND 'Merged' IN (\n      SELECT\n        name\n      FROM\n        UNNEST(pr.labels)\n    )\n),\n-- Get all the workflows run against the PR and find the steps & stats we care about\ncommit_job_durations AS (\n  SELECT\n    s.pr_number,\n    j.steps,\n    js.name AS step_name,\n    js.conclusion AS step_conclusion,\n    PARSE_TIMESTAMP_ISO8601(js.completed_at) AS failure_time,\n    PARSE_TIMESTAMP_ISO8601(js.started_at) AS start_time,\n    r.name AS workflow_name,\n    j.name AS job_name,\n    r.html_url AS workflow_url,\n    -- for debugging\n    s.sha,\n    j.conclusion AS conclusion,\n    j.conclusion = 'cancelled' AS was_cancelled,\n    -- For convenience\n    j.run_attempt,\n    -- the attemp number this job was run on\n    r.run_attempt AS total_attempts,\n    r.id AS workflow_run_id,\n    s.url -- for debugging\n  FROM\n    commons.workflow_job j\n    INNER JOIN merged_pr_shas s ON j.head_sha = s.sha HINT(join_strategy = lookup)\n    CROSS JOIN UNNEST (j.steps) js\n    INNER JOIN commons.workflow_run r ON j.run_id = r.id\n  WHERE\n    1 = 1\n    AND r.name = :workflow -- Stick to pull workflows to reduce noise. Trendlines are the same within other workflows\n    AND j.conclusion = 'failure' -- we just care about failed jobs\n    AND js.conclusion = 'failure'\n    AND j.run_attempt = 1 -- only look at the first run attempt since reruns will either 1) succeed, so are irrelevant or 2) repro the failure, biasing our data\n    and j.name NOT LIKE 'lintrunner%'\n    and j.name NOT LIKE '%unstable%' -- The PR doesn't wait for unstable jobs, so they should be excluded when computing TTRS\n    and js.name LIKE 'Test%' -- Only consider test steps\n    ),\n-- Refine our measurements to only collect the first red signal per workflow\n-- Gets the earliest TTRS across each workflow within the same commit\nworkflow_failure AS (\n  SELECT DISTINCT\n    d.pr_number,\n    d.sha,\n    d.workflow_run_id,\n    FIRST_VALUE(d.step_name) OVER(\n      PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n      ORDER BY d.failure_time\n    ) as step_name,\n    FIRST_VALUE(d.workflow_name) OVER(\n      PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n      ORDER BY d.failure_time\n    ) as workflow_name,\n    DURATION_SECONDS(\n      FIRST_VALUE(d.failure_time) OVER(\n        PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n        ORDER BY d.failure_time\n      ) -\n      FIRST_VALUE(d.start_time) OVER(\n        PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n        ORDER BY d.failure_time\n      )\n    ) / 60.0 as ttrs_mins,\n    FIRST_VALUE(d.workflow_url) OVER(\n      PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n      ORDER BY d.failure_time\n    ) as workflow_url,\n    FIRST_VALUE(d.start_time) OVER(\n      PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n      ORDER BY d.failure_time\n    ) as start_time,\n    FIRST_VALUE(d.failure_time) OVER(\n      PARTITION BY d.pr_number, d.sha, d.workflow_run_id\n      ORDER BY d.failure_time\n    ) as failure_time,\n  FROM\n    commit_job_durations d\n),\nworkflow_failure_buckets AS (\n  SELECT\n    -- When :one_bucket is set to true, we want the ttrs percentile over all the data\n    DATE_TRUNC(\n      'week',\n      IF(\n        : one_bucket,\n        CURRENT_DATETIME(),\n        start_time\n      )\n    ) AS bucket,\n    *\n  FROM\n    workflow_failure\n),\n-- Within each bucket, figure out what percentile duration and num_commits each PR falls under\npercentiles AS (\n  SELECT\n    bucket,\n    ttrs_mins,\n    workflow_url,\n    PERCENT_RANK() OVER(\n      PARTITION BY bucket\n      ORDER by\n        ttrs_mins\n    ) AS percentile,\n    sha,\n  FROM\n    workflow_failure_buckets\n),\n-- Take the full list of percentiles and get just the ones we care about\nttrs_percentile AS (\n  SELECT\n    p.bucket,\n    pd.percentile,\n    MIN(p.ttrs_mins) AS ttrs_mins\n  FROM\n    percentiles p CROSS\n    JOIN percentiles_desired pd\n  WHERE\n    1 = 1\n    AND p.percentile >= pd.percentile_num\n    AND (\n      : percentile_to_get <= 0\n      OR pd.percentile_num = : percentile_to_get\n    )\n  GROUP BY\n    p.bucket,\n    pd.percentile\n),\nkpi_results AS (\n  SELECT\n    FORMAT_TIMESTAMP('%Y-%m-%d', d.bucket) AS bucket,\n    -- rolling average\n    (\n      ROUND(AVG(ttrs_mins) OVER(\n        PARTITION BY percentile\n        ORDER BY\n          -- Average over this many + 1 buckets (two weeks)\n          bucket ROWS 0 PRECEDING\n      ))\n    ) AS ttrs_mins,\n    d.percentile\n  FROM\n    ttrs_percentile d\n  WHERE\n    : one_bucket\n    OR (\n      d.bucket < CURRENT_TIMESTAMP() - INTERVAL 1 WEEK\n    ) -- discard the latest bucket, which will have noisy, partial data\n  ORDER BY\n    bucket ASC,\n    ttrs_mins\n)\nSELECT\n  *\nFROM\n  kpi_results\nORDER BY\n  bucket DESC,\n  ttrs_mins DESC\n",
      "default_parameters": [
        {
          "name": "one_bucket",
          "type": "bool",
          "value": "False"
        },
        {
          "name": "percentile_to_get",
          "type": "float",
          "value": "0"
        },
        {
          "name": "startTime",
          "type": "string",
          "value": "2023-02-16T00:06:32.839Z"
        },
        {
          "name": "stopTime",
          "type": "string",
          "value": "2024-08-16T00:06:32.839Z"
        },
        {
          "name": "workflow",
          "type": "string",
          "value": "pull"
        }
      ]
    },
    "collections": [
      "commons.pull_request",
      "commons.workflow_run",
      "commons.workflow_job"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T16:28:38Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2024-06-17T17:23:49Z",
      "last_execution_error_message": "No value specified for query parameter \"startTime\". Please provide a value for this parameter and try again."
    },
    "public_access_id": null
  }
}