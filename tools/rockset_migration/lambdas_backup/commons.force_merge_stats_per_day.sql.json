{
  "query": "-- gets percentage of total force merges, force merges with failures, and force merges without failures (impatient)\nWITH\n    issue_comments AS(\n        SELECT\n            issue_comment.user.login,\n            issue_comment.author_association,\n            issue_comment.body,\n            issue_comment.issue_url,\n            issue_comment.html_url,\n            issue_comment.created_at,\n            issue_comment._event_time,\n            CAST(\n                SUBSTR(\n                    issue_comment.issue_url,\n                    LENGTH(\n                        'https://api.github.com/repos/pytorch/pytorch/issues/'\n                    ) + 1\n                ) as INT\n            ) as pr_num\n        FROM\n            commons.issue_comment\n        WHERE\n            (\n                issue_comment.body LIKE '%pytorchbot merge%'\n                OR issue_comment.body LIKE '%pytorchmergebot merge%'\n            ) -- AND _event_time >= PARSE_DATETIME_ISO8601(:startTime)\n            -- AND _event_time < PARSE_DATETIME_ISO8601(:stopTime)\n            AND issue_comment.user.login NOT LIKE '%pytorch-bot%'\n            AND issue_comment.user.login NOT LIKE '%facebook-github-bot%'\n            AND issue_comment.user.login NOT LIKE '%pytorchmergebot%'\n            AND issue_comment.issue_url LIKE '%https://api.github.com/repos/pytorch/pytorch/issues/%'\n    ),\n    all_merges AS (\n        SELECT\n            DISTINCT m.skip_mandatory_checks,\n            LENGTH(m.failed_checks) AS failed_checks_count,\n            m.ignore_current,\n            m.is_failed,\n            m.pr_num,\n            m.merge_commit_sha,\n            max(c._event_time) as time,\n        FROM\n            commons.merges m\n            inner join issue_comments c on m.pr_num = c.pr_num\n        WHERE\n            m.owner = 'pytorch'\n            AND m.project = 'pytorch'\n            AND m.merge_commit_sha != '' -- only consider successful merges\n            AND m._event_time >= PARSE_DATETIME_ISO8601(:startTime)\n            AND m._event_time < PARSE_DATETIME_ISO8601(:stopTime) -- AND m.pr_num in \n        GROUP BY\n            m.skip_mandatory_checks,\n            m.failed_checks,\n            m.ignore_current,\n            m.is_failed,\n            m.pr_num,\n            m.merge_commit_sha -- and m.pr_num = 104137\n    ),\n    force_merges_with_failed_checks AS (\n        SELECT\n            IF(\n                (skip_mandatory_checks = true)\n                OR (\n                    ignore_current = true\n                    AND is_failed = false\n                ),\n                1,\n                0\n            ) AS force_merge,\n            failed_checks_count,\n            pr_num,\n            merge_commit_sha,\n            time,\n        FROM\n            all_merges\n    ),\n    results as (\n        SELECT\n            pr_num,\n            merge_commit_sha,\n            force_merge,\n            IF(\n                (\n                    force_merge = 1\n                    AND failed_checks_count > 0\n                ),\n                1,\n                0\n            ) AS force_merge_with_failures,\n            CAST(time as DATE) as date\n        FROM\n            force_merges_with_failed_checks\n    ),\n    stats_per_day as (\n        select\n            sum(force_merge_with_failures) * 100 / count(*) as with_failures_percent,\n            (sum(force_merge) - sum(force_merge_with_failures)) * 100 / count(*) as impatience_percent,\n            date,\n        from\n            results\n        GROUP BY\n            date\n    ),\n    rolling_avg_stats_per_day as (\n        select\n            TRUNC(\n                SUM(with_failures_percent) OVER(\n                    ORDER BY\n                        date ROWS (28 -1) PRECEDING\n                ),\n                1\n            ) / 28 as with_failures_percent,\n            TRUNC(\n                SUM(impatience_percent) OVER(\n                    ORDER BY\n                        date ROWS (28 -1) PRECEDING\n                ),\n                1\n            ) / 28 as impatience_percent,\n            date,\n        from\n            stats_per_day\n    ),\n    final_table as (\n        (\n            select\n                date as granularity_bucket,\n                with_failures_percent as metric,\n                'from impatience' as name\n            from\n                rolling_avg_stats_per_day\n        )\n        UNION ALL\n        (\n            select\n                CAST(date as DATE) as granularity_bucket,\n                impatience_percent as metric,\n                'from failed tests' as name\n            from\n                rolling_avg_stats_per_day\n        )\n    )\nselect\n    CAST(CAST(granularity_bucket as DATETIME) as STRING) as granularity_bucket,\n    metric,\n    name\nfrom\n    final_table\n",
  "default_parameters": [
    {
      "name": "granularity",
      "type": "string",
      "value": "day"
    },
    {
      "name": "startTime",
      "type": "string",
      "value": "2023-01-01T11:00:00.000Z"
    },
    {
      "name": "stopTime",
      "type": "string",
      "value": "2023-07-27T00:00:00.000Z"
    }
  ]
}