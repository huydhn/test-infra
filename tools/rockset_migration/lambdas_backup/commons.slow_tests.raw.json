{
  "workspace": "commons",
  "last_updated_by": "darthsuo@gmail.com",
  "last_updated": "2022-06-30T20:43:39Z",
  "name": "slow_tests",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "commons.test_run_s3",
    "commons.push"
  ],
  "latest_version": {
    "workspace": "commons",
    "created_by": "darthsuo@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2022-06-30T20:43:39Z",
    "name": "slow_tests",
    "version": "ef8d035d23aa8ab6",
    "description": null,
    "sql": {
      "query": "WITH most_recent_strict_commits AS (\n    SELECT\n        push.head_commit.id as sha,\n    FROM\n        commons.push\n    WHERE\n        push.ref = 'refs/heads/viable/strict'\n        AND push.repository.full_name = 'pytorch/pytorch'\n    ORDER BY\n        push._event_time DESC\n    LIMIT\n        3\n), workflows AS (\n    SELECT\n        id\n    FROM\n        commons.workflow_run w\n        INNER JOIN most_recent_strict_commits c on w.head_sha = c.sha\n    WHERE\n        w.name != 'periodic'\n),\njob AS (\n    SELECT\n        j.id\n    FROM\n        commons.workflow_job j\n        INNER JOIN workflows w on w.id = j.run_id\n    WHERE\n        j.name NOT LIKE '%asan%'\n),\nduration_per_job AS (\n    SELECT\n        test_run.classname,\n        test_run.name,\n        job.id,\n        SUM(time) as time\n    FROM\n        commons.test_run_s3 test_run\n        /* `test_run` is ginormous and `job` is small, so lookup join is essential */\n        INNER JOIN job ON test_run.job_id = job.id HINT(join_strategy = lookup)\n    WHERE\n        /* cpp tests do not populate `file` for some reason. */\n        /* Exclude them as we don't include them in our slow test infra */\n        test_run.file IS NOT NULL\n        /* do some more filtering to cut down on the test_run size */\n        AND test_run.skipped IS NULL\n        AND test_run.failure IS NULL\n        AND test_run.error IS NULL\n    GROUP BY\n        test_run.classname,\n        test_run.name,\n        job.id\n)\nSELECT\n    CONCAT(\n        name,\n        ' (__main__.',\n        classname,\n        ')'\n    ) as test_name,\n    AVG(time) as avg_duration_sec\nFROM\n    duration_per_job\nGROUP BY\n    CONCAT(\n        name,\n        ' (__main__.',\n        classname,\n        ')'\n    )\nHAVING\n    AVG(time) > 60.0\nORDER BY\n    test_name\n",
      "default_parameters": []
    },
    "collections": [
      "commons.push",
      "commons.workflow_run",
      "commons.workflow_job",
      "commons.test_run_s3"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-24T21:12:47Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": "2023-03-28T21:14:02Z",
      "last_execution_error_message": "Query timeout reached. Enable Asynchronous Mode via the `async_options` request field to extend the query timeout duration for this query."
    },
    "public_access_id": null
  }
}