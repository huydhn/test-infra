{
  "query": "--- This query is used by HUD metrics page to get the list of queued jobs grouped by their labels\nWITH queued_jobs as (\n  SELECT\n    DATE_DIFF(\n      'second',\n      job._event_time,\n      CURRENT_TIMESTAMP()\n    ) AS queue_s,\n    CONCAT(workflow.name, ' / ', job.name) AS name,\n    job.html_url,\n    IF(\n      LENGTH(job.labels) = 0,\n      IF (\n        job.runner_group_name IS NOT null\n        AND job.runner_group_name != 'Default'\n        AND job.runner_group_name != 'GitHub Actions'\n        AND job.runner_group_name != ''\n        AND job.runner_group_name != 'linux.rocm.gpu.group',\n        job.runner_group_name,\n        'N/A'\n      ),\n      IF(\n        LENGTH(job.labels) > 1,\n        ELEMENT_AT(job.labels, 2),\n        ELEMENT_AT(job.labels, 1)\n      )\n    ) AS machine_type,\n  FROM\n    commons.workflow_job job\n    JOIN commons.workflow_run workflow ON workflow.id = job.run_id\n  WHERE\n    workflow.repository.full_name = 'pytorch/pytorch'\n    AND job.status = 'queued'\n    AND job._event_time < (\n      CURRENT_TIMESTAMP() - INTERVAL 5 MINUTE\n    )\n    /* These two conditions are workarounds for GitHub's broken API. Sometimes */\n    /* jobs get stuck in a permanently \"queued\" state but definitely ran. We can */\n    /* detect this by looking at whether any steps executed (if there were, */\n    /* obviously the job started running), and whether the workflow was marked as */\n    /* complete (somehow more reliable than the job-level API) */\n    AND LENGTH(job.steps) = 0\n    AND workflow.status != 'completed'\n  ORDER BY\n    queue_s DESC\n)\nSELECT\n  COUNT(*) AS count,\n  MAX(queue_s) AS avg_queue_s,\n  machine_type,\nFROM\n  queued_jobs\nGROUP BY\n  machine_type\nORDER BY\n  count DESC\n",
  "default_parameters": []
}