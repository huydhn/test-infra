{
  "workspace": "metrics",
  "last_updated_by": "zainriz3@gmail.com",
  "last_updated": "2023-04-11T15:50:44Z",
  "name": "completed_pr_jobs_aggregate",
  "version_count": 1,
  "collections": [
    "commons.workflow_job",
    "commons.workflow_run",
    "commons.pull_request"
  ],
  "latest_version": {
    "workspace": "metrics",
    "created_by": "zainriz3@gmail.com",
    "created_by_apikey_name": null,
    "created_at": "2023-04-11T15:50:44Z",
    "name": "completed_pr_jobs_aggregate",
    "version": "7b6b27eeca4dfc6f",
    "description": "Intermediate data for the CI Wait TIme kpi",
    "sql": {
      "query": "-- This query is used to generate the CI Wait Time KPI for the pytorch/pytorch repo\n-- It's not the full kpi. Rather, this performs some early data processing and aggregation, which\n-- is then used by a python script to generate the final KPI, which gets uploaded back to rockset \n-- to be generally queryable\nWITH\n    -- Get all PRs that were merged into master, and get all the SHAs for commits from that PR which CI jobs ran against\n    -- We need the shas because some jobs (like trunk) don't have a PR they explicitly ran against, but they _were_ run against\n    -- a commit from a PR\n    pr_shas AS (\n        SELECT  \n            r.pull_requests[1].number AS pr_number,\n            CONCAT(\n                'https://github.com/pytorch/pytorch/pull/',\n                r.pull_requests[1].number\n            ) AS url,\n            j.head_sha AS sha,\n        FROM\n            commons.workflow_job j\n            INNER JOIN commons.workflow_run r on j.run_id = r.id\n        WHERE\n            1 = 1\n            AND j._event_time > (\n                CURRENT_DATETIME() - DAYS(:from_days_ago)\n            )\n            AND r._event_time > (\n                CURRENT_DATETIME() - DAYS(:from_days_ago)\n            )\n            AND j._event_time < (CURRENT_DATETIME() - DAYS(:to_days_ago))\n            AND r._event_time < (CURRENT_DATETIME() - DAYS(:to_days_ago))\n            AND LENGTH(r.pull_requests) = 1\n            AND r.head_branch NOT IN ('master', 'main', 'nightly', 'viable/strict')\n            AND r.pull_requests[1].head.repo.name = 'pytorch'\n            AND r.name IN ('pull', 'trunk', 'Lint') \n            -- Ensure we don't pull in random PRs we don't care about\n            AND (\n                r.pull_requests[1].base.ref = 'master'\n                OR r.pull_requests[1].base.ref = 'main'\n                OR r.pull_requests[1].base.ref like 'gh/%/base'\n            )\n        GROUP BY\n            pr_number,\n            url,\n            sha\n    ),\n    -- Now filter the list to just closed PRs\n    merged_pr_shas AS (\n        SELECT  \n            DISTINCT s.pr_number,\n            s.url,\n            s.sha\n        FROM\n            pr_shas s\n            INNER JOIN commons.pull_request pr on s.pr_number = pr.number\n        WHERE\n            pr.closed_at IS NOT NULL \n            -- Ensure the PR was actaully merged\n            AND 'Merged' IN (\n                SELECT  \n                    name\n                FROM\n                    UNNEST(pr.labels)\n            )\n    ),\n    -- Get all the workflows and partially aggregate the jobs run against each commit (based on the job's conclusion)\n    commit_job_durations AS (\n        SELECT  \n            s.pr_number,\n            r.name AS workflow_name,\n            s.sha,\n            j.conclusion AS conclusion,\n            j.conclusion = 'cancelled' AS was_cancelled, -- For convenience\n            j.run_attempt, -- the attemp # this job was run on\n            r.run_attempt AS total_attempts,\n            r.id AS workflow_run_id,\n            min(r.run_started_at) AS start_time,\n            max(PARSE_TIMESTAMP_ISO8601(j.completed_at)) AS end_time,\n            DATE_DIFF(\n                'MINUTE',\n                min(j._event_time),\n                max(PARSE_TIMESTAMP_ISO8601(j.completed_at))\n            ) AS duration_mins,\n            r.html_url AS workflow_url, -- for debugging\n            s.url, -- for debugging \n        FROM\n            commons.workflow_job j\n            INNER JOIN merged_pr_shas s on j.head_sha = s.sha\n            INNER JOIN commons.workflow_run r on j.run_id = r.id\n        WHERE\n            1 = 1\n            AND (\n                r.name IN ('pull', 'trunk', 'Lint')\n                OR r.name like 'linux-binary%'\n                OR r.name like 'windows-binary%'\n            ) \n            -- skipped jobs are irrelevant to us\n            AND j.conclusion NOT IN ('skipped')\n        GROUP BY\n            pr_number,\n            workflow_name,\n            url,\n            sha,\n            run_attempt,\n            total_attempts,\n            conclusion,\n            was_cancelled,\n            workflow_run_id,\n            workflow_url\n    )\nSELECT\n    *\nFROM\n    commit_job_durations\nORDER BY pr_number DESC",
      "default_parameters": [
        {
          "name": "from_days_ago",
          "type": "int",
          "value": "30"
        },
        {
          "name": "to_days_ago",
          "type": "int",
          "value": "0"
        }
      ]
    },
    "collections": [
      "commons.pull_request",
      "commons.workflow_run",
      "commons.workflow_job"
    ],
    "state": "ACTIVE",
    "stats": {
      "last_executed": "2024-06-25T05:01:24Z",
      "last_executed_by": "darthsuo@gmail.com",
      "last_execution_error": null,
      "last_execution_error_message": null
    },
    "public_access_id": null
  }
}