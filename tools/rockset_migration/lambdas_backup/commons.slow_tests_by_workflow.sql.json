{
  "query": "WITH\n    shas AS (\n        (\n            select\n                job.head_sha as sha\n            from\n                commons.workflow_job job\n                JOIN commons.workflow_run workflow on workflow.id = job.run_id\n                JOIN push on workflow.head_commit.id = push.head_commit.id\n            where\n                workflow.name = :workflow\n                AND workflow.head_branch LIKE 'main'\n            group by\n                job.head_sha,\n                push._event_time\n            having\n                BOOL_AND(\n                    job.conclusion = 'success'\n                    and job.conclusion is not null\n                )\n            order by\n                push._event_time desc\n            limit\n                3\n        )\n        union\n        (\n            select\n                job.head_sha as sha\n            from\n                commons.workflow_job job\n                JOIN commons.workflow_run workflow on workflow.id = job.run_id\n                JOIN push on workflow.head_commit.id = push.head_commit.id\n            where\n                workflow.name = :workflow\n                AND workflow.head_branch LIKE 'main'\n            group by\n                job.head_sha,\n                push._event_time\n            having\n                BOOL_AND(job.conclusion is not null)\n            order by\n                push._event_time desc\n            limit\n                1\n        )\n    ), workflows AS (\n        SELECT\n            id\n        FROM\n            commons.workflow_run w\n            INNER JOIN shas c on w.head_sha = c.sha\n        WHERE\n            w.name = :workflow\n    ),\n    job AS (\n        SELECT\n            j.id,\n            REGEXP_EXTRACT(j.name, '^(.*) /', 1) as base_name,\n        FROM\n            commons.workflow_job j\n            INNER JOIN workflows w on w.id = j.run_id\n    ),\n    duration_per_job AS (\n        SELECT\n            test_run.classname,\n            test_run.name,\n            job.base_name,\n            job.id,\n            SUM(time) as time\n        FROM\n            commons.test_run_s3 test_run\n            /* test_run is ginormous and job is small, so lookup join is essential */\n            INNER JOIN job ON test_run.job_id = job.id HINT(join_strategy = lookup)\n        WHERE\n            /* cpp tests do not populate file for some reason. */\n            /* Exclude them as we don't include them in our slow test infra */\n            test_run.file IS NOT NULL\n            /* do some more filtering to cut down on the test_run size */\n            AND test_run.skipped IS NULL\n            AND test_run.failure IS NULL\n            AND test_run.error IS NULL\n        GROUP BY\n            test_run.classname,\n            test_run.name,\n            job.id,\n            job.base_name\n    )\nSELECT\n    CONCAT(name, ' (__main__.', classname, ')') as test_name,\n    AVG(time) as avg_duration_sec,\n    base_name,\nFROM\n    duration_per_job\nGROUP BY\n    CONCAT(name, ' (__main__.', classname, ')'),\n    base_name\nHAVING\n    AVG(time) > 60.0\nORDER BY\n    test_name\n",
  "default_parameters": [
    {
      "name": "workflow",
      "type": "string",
      "value": "slow"
    }
  ]
}